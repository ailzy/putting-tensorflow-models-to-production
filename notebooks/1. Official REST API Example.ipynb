{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Productionizing\n",
    "- In this notebook, we are going to do an official REST API example where we are going to retrieve a fashion dataset that is open sourced by Zalando and then train a keras model.\n",
    "- Then, we are going to save this model locally.\n",
    "- Then, we are going to put a REST API and then get the predictions served by Tensorflow Model Serving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "FROM ubuntu:16.04\n",
    "LABEL maintainer=\"bugra@ymail.com\"\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "        curl \\\n",
    "        gnupg\n",
    "\n",
    "RUN echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list\n",
    "ENV APT_KEY_DONT_WARN_ON_DANGEROUS_USAGE=1\n",
    "RUN curl -s https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "        tensorflow-model-server\n",
    "\n",
    "RUN  apt-get clean && \\\n",
    "        rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN mkdir -p /app/models /app/tf_serving_scripts\n",
    "COPY models/fashion_mnist/ /app/models\n",
    "COPY fashion_mnist.sh /app/tf_serving_scripts\n",
    "\n",
    "# GRPC Port\n",
    "EXPOSE 8500\n",
    "# HTTP REST API Port\n",
    "EXPOSE 8501  \n",
    "\n",
    "ENTRYPOINT [\"/bin/sh\", \"/app/tf_serving_scripts/fashion_mnist.sh\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tensorflow_model_server --rest_api_port=8501 --model_name=fashion_model --model_base_path=\"/app/models\" \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "\n",
    "# 3rd Party\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATUS_URL = 'http://localhost:8501/v1/models/fashion_model'\n",
    "METADATA_URL = 'http://localhost:8501/v1/models/fashion_model/metadata'\n",
    "PREDICTION_URL = 'http://localhost:8501/v1/models/fashion_model:predict'\n",
    "FIRST_VERSION_PREDICTION_URL = 'http://localhost:8501/v1/models/fashion_model/versions/1:predict'\n",
    "HEADERS = {\"content-type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape: (60000, 28, 28, 1), of float64\n",
      "test_images.shape: (10000, 28, 28, 1), of float64\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# scale the values to 0.0 to 1.0\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# reshape for feeding into the model\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print('train_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
    "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1 (Conv2D)               (None, 13, 13, 8)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "Softmax (Dense)              (None, 10)                13530     \n",
      "=================================================================\n",
      "Total params: 13,610\n",
      "Trainable params: 13,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.5335 - acc: 0.8196\n",
      "Epoch 2/5\n",
      "32512/60000 [===============>..............] - ETA: 1s - loss: 0.3809 - acc: 0.8675"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, \n",
    "                      strides=2, activation='relu', name='Conv1'),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "testing = False\n",
    "epochs = 5\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=epochs)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('\\nTest accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Keras session and save the model\n",
    "# The signature definition is defined by the input and output tensors,\n",
    "# and stored with the default serving key\n",
    "\n",
    "\n",
    "MODEL_DIR = 'models'\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "if os.path.isdir(export_path):\n",
    "  print('\\nAlready saved a model, cleaning up\\n')\n",
    "  !rm -r {export_path}\n",
    "\n",
    "tf.saved_model.simple_save(\n",
    "    keras.backend.get_session(),\n",
    "    export_path,\n",
    "    inputs={'input_image': model.input},\n",
    "    outputs={t.name:t for t in model.outputs})\n",
    "\n",
    "print('\\nSaved model:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(idx, title):\n",
    "  plt.figure(figsize=(16, 12))\n",
    "  plt.imshow(test_images[idx].reshape(28,28), cmap='Greys')\n",
    "  plt.axis('off')\n",
    "  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n",
    "\n",
    "rando = random.randint(0,len(test_images)-1)\n",
    "show(rando, 'An Example Image: {}'.format(class_names[test_labels[rando]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:4].tolist()})\n",
    "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status of the model\n",
    "requests.get(STATUS_URL).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "requests.get(METADATA_URL).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = requests.post(PREDICTION_URL, data=data, headers=HEADERS)\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "show(0, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(\n",
    "  class_names[np.argmax(predictions[0])], test_labels[0], class_names[test_labels[0]], test_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_show(items, titles):\n",
    "  f, axarr = plt.subplots(2,2, figsize=(16, 12))\n",
    "  axarr[0,0].imshow(test_images[0].reshape(28,28), cmap='Greys')\n",
    "  axarr[0,0].set_title('\\n\\n{}'.format(titles[0]))\n",
    "  axarr[0,1].imshow(test_images[1].reshape(28,28), cmap='Greys')\n",
    "  axarr[0,1].set_title('\\n\\n{}'.format(titles[1]))\n",
    "  axarr[1,0].imshow(test_images[2].reshape(28,28), cmap='Greys')\n",
    "  axarr[1,0].set_title('\\n\\n{}'.format(titles[2]))\n",
    "  axarr[1,1].imshow(test_images[3].reshape(28,28), cmap='Greys')\n",
    "  axarr[1,1].set_title('\\n\\n{}'.format(titles[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = requests.post(FIRST_VERSION_PREDICTION_URL, data=data, headers=HEADERS)\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "items = []\n",
    "titles = []\n",
    "for i in range(0,4):\n",
    "  items.append(i)\n",
    "  titles.append('Model={}, Actual={}'.format(\n",
    "    class_names[np.argmax(predictions[i])], class_names[test_labels[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_show(items, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
